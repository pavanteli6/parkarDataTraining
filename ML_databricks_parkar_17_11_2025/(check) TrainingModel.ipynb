{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38821fd3-bb04-4716-82d2-e03600821278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Diabetes Prediction Machine Learning Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d5d1aba-6020-45fd-bca7-73097b83fe8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loading Dataset into the databricks file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2080a2b1-570d-4015-b39f-9a4aedda9427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  %sh\n",
    "#  rm -r /dbfs/ml_lab\n",
    "#  mkdir /dbfs/ml_lab\n",
    "#  wget -O /dbfs/ml_lab/diabetes.csv https://raw.githubusercontent.com/kuljotSB/DatabricksUdemyCourse/refs/heads/main/MachineLearningModel/diabetes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "881f2363-fb9c-4ad0-b115-9cf7b938478d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Exploring and Cleaning the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a04a183-33a9-439a-826b-7b7aaf2c1177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls 'abfss://landing@parkaru15sa.dfs.core.windows.net/ML model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b77ce8a-b342-4768-81eb-7c69456deb0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"abfss://landing@parkaru15sa.dfs.core.windows.net/ML model/\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d932d2-0140-4f0f-8c16-c89ad28fa4ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "   \n",
    "data = df.dropna().select(col(\"Pregnancies\").astype(\"int\"),\n",
    "                           col(\"Glucose\").astype(\"int\"),\n",
    "                          col(\"BloodPressure\").astype(\"int\"),\n",
    "                          col(\"SkinThickness\").astype(\"int\"),\n",
    "                          col(\"Insulin\").astype(\"int\"),\n",
    "                          col(\"BMI\").astype(\"float\"),\n",
    "                          col(\"DiabetesPedigreeFunction\").astype(\"float\"),\n",
    "                          col(\"Age\").astype(\"int\"),\n",
    "                          col(\"Outcome\").astype(\"int\")\n",
    "                          )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21d3eddb-0f31-4688-aaa9-afbdf851ac9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae2e5d0a-7c8f-45f4-8ce5-eac22facf2d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "print (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6fe85c1-5763-44a4-91e7-528dab40b454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Performing Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cddebe73-71dc-4270-97e8-984bf8dc40fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Normalizing/scaling our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87aa486d-8c3e-4bb2-b01c-00332d3fa4ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "numericFeatures = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"]\n",
    "numericColVector = VectorAssembler(inputCols=numericFeatures, outputCol = \"numericFeatures\")\n",
    "vectorizedData = numericColVector.transform(train)\n",
    "\n",
    "minMax = MinMaxScaler(inputCol= numericColVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "scaledData = minMax.fit(vectorizedData).transform(vectorizedData)\n",
    "\n",
    "compareNumerics = scaledData.select(\"numericFeatures\", \"normalizedFeatures\")\n",
    "display(compareNumerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aab39234-e73b-4c7d-b154-e69d1c0b6119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Preparing the features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98df6ba8-9bc2-4d53-97f1-584462253336",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preppedData = scaledData[col(\"normalizedFeatures\").alias(\"features\"), col(\"Outcome\").alias(\"label\")]\n",
    "display(preppedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2560449-fe50-4383-aed9-5c16d4fb40e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25556a1b-7331-4b80-a9ce-8ae630d70058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.3)\n",
    "model = lr.fit(preppedData)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fc79881-7902-4bba-bbde-7e08462fea45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Testing the prepared model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a909d9-6b27-4f88-9971-bc78004ffc4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "\n",
    "vectorizedTestData = numericColVector.transform(test)\n",
    "scaledTestData = minMax.fit(vectorizedTestData).transform(vectorizedTestData)\n",
    "preppedTestData = scaledTestData[col(\"normalizedFeatures\").alias(\"features\"), col(\"Outcome\").alias(\"label\")]\n",
    "   \n",
    "# Get predictions\n",
    "prediction = model.transform(preppedTestData)\n",
    "predicted = prediction.select(\"features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"label\").alias(\"trueLabel\"))\n",
    "display(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38706522-5bc8-41f0-96ce-5f116411d723",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Evaluating Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00ca39a0-215e-4482-bc22-bc869e28bb93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "   \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "   \n",
    "# Simple accuracy\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName:\"accuracy\"})\n",
    "print(\"Accuracy:\", accuracy)\n",
    "   \n",
    "# Individual class metrics\n",
    "labels = [0,1]\n",
    "print(\"\\nIndividual class metrics:\")\n",
    "for label in sorted(labels):\n",
    "    print (\"Class %s\" % (label))\n",
    "   \n",
    "    # Precision\n",
    "    precision = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                                evaluator.metricName:\"precisionByLabel\"})\n",
    "    print(\"\\tPrecision:\", precision)\n",
    "   \n",
    "    # Recall\n",
    "    recall = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                             evaluator.metricName:\"recallByLabel\"})\n",
    "    print(\"\\tRecall:\", recall)\n",
    "   \n",
    "    # F1 score\n",
    "    f1 = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                         evaluator.metricName:\"fMeasureByLabel\"})\n",
    "    print(\"\\tF1 Score:\", f1)\n",
    "   \n",
    "# Weighted (overall) metrics\n",
    "overallPrecision = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedPrecision\"})\n",
    "print(\"Overall Precision:\", overallPrecision)\n",
    "overallRecall = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedRecall\"})\n",
    "print(\"Overall Recall:\", overallRecall)\n",
    "overallF1 = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedFMeasure\"})\n",
    "print(\"Overall F1 Score:\", overallF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbeb7775-e901-41e5-9d55-d62139cdf635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using a Pipeline for Encapsulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d24c693-e85c-449e-8750-5a15ce9a80ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "   \n",
    "\n",
    "numFeatures = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "   \n",
    "# Define the feature engineering and model training algorithm steps\n",
    "numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "featureVector = VectorAssembler(inputCols=[\"normalizedFeatures\"], outputCol=\"Features\")\n",
    "algo = LogisticRegression(labelCol=\"Outcome\", featuresCol=\"Features\", maxIter=10, regParam=0.3)\n",
    "   \n",
    "# Chain the steps as stages in a pipeline\n",
    "pipeline = Pipeline(stages=[ numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "# Use the pipeline to prepare data and fit the model algorithm\n",
    "model = pipeline.fit(train)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "140be9ee-442f-4c43-917e-e3f6b06f638f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Use the pipline to inference prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493928f8-bab4-43ac-a5d5-83ece8154533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"Features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"Outcome\").alias(\"trueLabel\"))\n",
    "display(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c351aab-2338-4c5a-8aa3-f79d62ac2b0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11b4fe79-e9c9-4822-8772-1cb43324de00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog newpavancatalog;\n",
    "use schema bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4085dad7-b3c0-49d5-b482-99f19fa10043",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.write().overwrite().save(\"/models/diabetes.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1296d35-9e56-4afd-aa48-1540444d3d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Locally Inferencing our Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb81676e-61f9-4438-bae9-0f6e6a70c428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "persistedModel = PipelineModel.load(\"/models/diabetes.model\")\n",
    "   \n",
    "newData = spark.createDataFrame ([{\"Pregnancies\": 8,\n",
    "                                  \"Glucose\": 85,\n",
    "                                  \"BloodPressure\": 65,\n",
    "                                  \"SkinThickness\": 29,\n",
    "                                  \"Insulin\": 0,\n",
    "                                  \"BMI\": 26.6,\n",
    "                                  \"DiabetesPedigreeFunction\": 0.672,\n",
    "                                  \"Age\": 34\n",
    "                                  }])\n",
    "   \n",
    "   \n",
    "predictions = persistedModel.transform(newData)\n",
    "display(predictions.select(\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\",  col(\"prediction\").alias(\"PredictedOutcome\")))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8240537583318157,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(check) TrainingModel",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
